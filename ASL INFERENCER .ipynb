{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reasonable-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heavy-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load and prepare data##\n",
    "#load data from CSV files located in /data/asl_data/\n",
    "train_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")\n",
    "\n",
    "#separate out target values\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "#separate out image vectors \n",
    "x_train = train_df.values\n",
    "x_valid = valid_df.values\n",
    "\n",
    "#turn our scalar targets into binary, using 24 classes\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "#normalize image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naval-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reshape data for Convolutional Neural Network##\n",
    "#reshape from 784 single vector to (3D 28,28,1) with a single color channel\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "robust-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create layers for Convolutional model##\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "#Convolutional layer, filter/kernel=75, window of 3x3, input shape is image of 28,28 with color channel of 1\n",
    "model.add(Conv2D(75, (3,3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "#MaxPool Highlight most present feature in patch\n",
    "model.add(MaxPool2D((2,2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "#Dropout to prevent overfitting\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(25, (3,3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2), strides=2, padding=\"same\"))\n",
    "#Flatten to reduce 3D structure to a single dimension appropriate to run through Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(units=num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "protected-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                12312     \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Getting Model summary and seeing parameter count\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "smart-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compile Model using Categorical Crossentropy loss function and using accuracy as a metric##\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "social-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "858/858 [==============================] - 42s 48ms/step - loss: 0.8257 - accuracy: 0.7594 - val_loss: 0.4743 - val_accuracy: 0.8516\n",
      "Epoch 2/20\n",
      "858/858 [==============================] - 44s 51ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.3865 - val_accuracy: 0.9090\n",
      "Epoch 3/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.3437 - val_accuracy: 0.9191\n",
      "Epoch 4/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.2232 - val_accuracy: 0.9504\n",
      "Epoch 5/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.2826 - val_accuracy: 0.9452\n",
      "Epoch 6/20\n",
      "858/858 [==============================] - 44s 51ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2079 - val_accuracy: 0.9594\n",
      "Epoch 7/20\n",
      "858/858 [==============================] - 45s 53ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.2155 - val_accuracy: 0.9596\n",
      "Epoch 8/20\n",
      "858/858 [==============================] - 46s 53ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4345 - val_accuracy: 0.9318\n",
      "Epoch 9/20\n",
      "858/858 [==============================] - 44s 51ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.3338 - val_accuracy: 0.9481\n",
      "Epoch 10/20\n",
      "858/858 [==============================] - 44s 52ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2646 - val_accuracy: 0.9629\n",
      "Epoch 11/20\n",
      "858/858 [==============================] - 45s 52ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.4507 - val_accuracy: 0.9476\n",
      "Epoch 12/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3884 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2714 - val_accuracy: 0.9565\n",
      "Epoch 14/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 9.6998e-04 - accuracy: 0.9998 - val_loss: 0.3916 - val_accuracy: 0.9642\n",
      "Epoch 15/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4418 - val_accuracy: 0.9391\n",
      "Epoch 16/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.4370 - val_accuracy: 0.9499\n",
      "Epoch 17/20\n",
      "858/858 [==============================] - 43s 50ms/step - loss: 8.3723e-04 - accuracy: 0.9997 - val_loss: 0.3924 - val_accuracy: 0.9596\n",
      "Epoch 18/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.6158 - val_accuracy: 0.9654\n",
      "Epoch 19/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.5908 - val_accuracy: 0.9571\n",
      "Epoch 20/20\n",
      "858/858 [==============================] - 42s 49ms/step - loss: 3.5687e-04 - accuracy: 0.9999 - val_loss: 0.4822 - val_accuracy: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x223c88347f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Train Model##\n",
    "model.fit(x_train, y_train, epochs=20, verbose = 1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "circular-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Visualization of predictions\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt #Visualize sample\n",
    "import numpy as np #ARGMAX : Argmax is most commonly used in machine learning for finding the class with the largest predicted probability\n",
    "\n",
    "model.save('test.model')\n",
    "new_model = tf.keras.models.load_model('test.model')\n",
    "predictions = new_model.predict([x_valid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "prime-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dictionary to Map Category to Letter\n",
    "numtoletter = {\n",
    "  0: \"A\",\n",
    "  1: \"B\",\n",
    "  2: \"C\",\n",
    "  3: \"D\",\n",
    "  4: \"E\",\n",
    "  5: \"F\",\n",
    "  6: \"G\",\n",
    "  7: \"H\",\n",
    "  8: \"I\",\n",
    "  9: \"K\",\n",
    "  10: \"L\",\n",
    "  11: \"M\",\n",
    "  12: \"N\",\n",
    "  13: \"O\",\n",
    "  14: \"P\",\n",
    "  15: \"Q\",\n",
    "  16: \"R\",\n",
    "  17: \"S\",\n",
    "  18: \"T\",\n",
    "  19: \"U\",\n",
    "  20: \"V\",\n",
    "  21: \"W\",\n",
    "  22: \"X\",\n",
    "  23: \"Y\",  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "convertible-impression",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sign represents a letter O\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to visualize training results place a number for p within the range 0 - 7000\n",
    "p = 7\n",
    "print(\"this sign represents a letter\", numtoletter[np.argmax(predictions[p])] )\n",
    "plt.imshow(x_valid[p])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-jimmy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
